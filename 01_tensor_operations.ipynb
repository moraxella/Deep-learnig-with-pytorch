{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "01-tensor-operations.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moraxella/Deep-learnig-with-pytorch/blob/main/01_tensor_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adOqR8ghra_I",
        "outputId": "2fe49610-510a-41a7-9aee-7ee78a9b3d80"
      },
      "source": [
        "# Jovian Commit Essentials\n",
        "# Please retain and execute this cell without modifying the contents for `jovian.commit` to work\n",
        "!pip install jovian --upgrade -q\n",
        "import jovian\n",
        "jovian.utils.colab.set_colab_file_id('1L9gqVGzrKZMbxzsFoB_Jf_x6SdFy01JP')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████                           | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 25.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25h  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HCLYnTfra_O"
      },
      "source": [
        "# PyTorch tensor operations \n",
        "\n",
        "An short introduction about PyTorch and about the chosen functions. \n",
        "\n",
        "- TORCH.LINSPACE\n",
        ">Creates a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive. That is, the value are \n",
        "![Screenshot from 2020-12-24 15-00-17.png](data:image/png;base64,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)\n",
        "- TORCH.CAT\n",
        ">Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty.\n",
        "- TORCH.CHUNK\n",
        ">Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.\n",
        "- TORCH.BERNOULLI\n",
        ">Draws binary random numbers (0 or 1) from a Bernoulli distribution.\n",
        "- TORCH.RANDINT\n",
        ">Returns a tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive). The shape of the tensor is defined by the variable argument size.\n",
        "\n",
        "Before we begin, let's install and import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTwiuUpFra_P"
      },
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnOboxvTra_Q"
      },
      "source": [
        "# Import torch and other required modules\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E5AK9V5ra_Q"
      },
      "source": [
        "## Function 1 - TORCH.LINESPACE\n",
        "\n",
        "Creates one-dimensional tensor in which all the values are evenly spaced from startig to the end. Take several arguments, torch.linespace(start, end, steps). Start indicating the float type starting values, end indicating teh float type ending values and the steps indicating the int type size of constructed tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YuoFZk3ra_R",
        "outputId": "f53f265a-c031-42d6-a458-17782dc34283"
      },
      "source": [
        "# Example 1 - working (change this)\n",
        "torch.linspace(3, 10, steps=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.0000,  4.7500,  6.5000,  8.2500, 10.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiejz_1Cra_T"
      },
      "source": [
        "Explanation about example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkwDLxAMra_U",
        "outputId": "e800fb4a-5b49-446b-922e-e9da6f73c2bd"
      },
      "source": [
        "# Example 2 - working\n",
        "torch.linspace(-10, 20, steps=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.0000e+01, -6.6667e+00, -3.3333e+00, -2.3842e-07,  3.3333e+00,\n",
              "         6.6667e+00,  1.0000e+01,  1.3333e+01,  1.6667e+01,  2.0000e+01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G-VymiLra_U"
      },
      "source": [
        "Simply getting the tensor of evenly spaced values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "Cqve942bra_U",
        "outputId": "ea10f193-c05a-45b5-8ca6-8650fae6d7c5"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.linspace(-3, steps=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ea6043610360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: linspace() missing 1 required positional arguments: \"end\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jOwqX29ra_V"
      },
      "source": [
        "These three arguments are necessary to use this function otherwise it will pop-up to show the TypeError for missing arguments "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB94gkLara_W"
      },
      "source": [
        "Let's save our work using Jovian before continuing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JB-MTb_ra_W"
      },
      "source": [
        "!pip install jovian --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KACjvJHNra_W"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "jAdrt5aqra_X",
        "outputId": "19276d6b-a5c3-4f9f-cc79-442ef4e221ee"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY: ··········\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/ankitsainiz865/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/ankitsainiz865/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42-NG1zsra_X"
      },
      "source": [
        "## Function 2 - TORCH.CAT\n",
        "\n",
        "This functions used for the concatenation of different tensors of given shape accordingly. There is one condition that we should have to take care is the shape of tensors must be same so that they can easily concatenate otherwise it will show error.\n",
        "\n",
        "- torch.cat(tensors, dim=0, *, out=None) → Tensor\n",
        ">Here the tensors are any python sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension. While the dim is the dimension over which the tensors are concatenated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRwphrMera_X",
        "outputId": "cb7bebf4-8917-408a-ae33-297653cc386f"
      },
      "source": [
        "# Example 1 - working\n",
        "x = torch.randn(2, 3)\n",
        "print (torch.cat((x, x, x), 0))\n",
        "print (torch.cat((x, x, x), 0).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8876,  1.7742,  1.3670],\n",
            "        [-0.2666,  1.1613,  0.0221],\n",
            "        [-0.8876,  1.7742,  1.3670],\n",
            "        [-0.2666,  1.1613,  0.0221],\n",
            "        [-0.8876,  1.7742,  1.3670],\n",
            "        [-0.2666,  1.1613,  0.0221]])\n",
            "torch.Size([6, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qW6_gfEra_Y"
      },
      "source": [
        "Here the tensors concatenate along the dimension zero along y-axis, which make it of size 6 * 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJXmdH8Qra_Y",
        "outputId": "0c43bd2a-a0e4-4bae-f6f4-28ade2931ede"
      },
      "source": [
        "# Example 2 - working\n",
        "print (torch.cat((x,x,x,x), 1))\n",
        "print (torch.cat((x,x,x,x), 1).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.2306,  0.5518,  0.3757,  1.2306,  0.5518,  0.3757,  1.2306,  0.5518,\n",
            "          0.3757,  1.2306,  0.5518,  0.3757],\n",
            "        [-2.0284, -0.7433,  0.3298, -2.0284, -0.7433,  0.3298, -2.0284, -0.7433,\n",
            "          0.3298, -2.0284, -0.7433,  0.3298]])\n",
            "torch.Size([2, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXVGAGGra_Y"
      },
      "source": [
        "Here the tensors concatenate along the dimension zero along x-axis, which make it of size 2 * 12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xa0A2pxCra_Y",
        "outputId": "c7661daf-abb5-4f37-8676-be2212ea2066"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "y = torch.randn(2, 3)\n",
        "z = torch.randn(3, 2)\n",
        "print (y)\n",
        "print (z)\n",
        "torch.cat((y, z), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8192, -0.4117, -0.0622],\n",
            "        [ 0.0200, -2.1774,  0.6276]])\n",
            "tensor([[-0.5870,  0.4779],\n",
            "        [-0.2419, -0.8842],\n",
            "        [ 0.4357, -0.1209]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6dc93101e9d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Got 2 and 3 in dimension 0 (The offending index is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwO5cIqUra_Z"
      },
      "source": [
        "Here we are, its showing how important the size of tensor is for the concatenation otherwise it will lead to the error as shown above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "CDCbUwJDra_Z",
        "outputId": "c259bb62-1dad-4d2e-db03-7372a75bb031"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/ankitsainiz865/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/ankitsainiz865/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F0DaPVara_a"
      },
      "source": [
        "## Function 3 - TORCH.CHUNK\n",
        "\n",
        "This function is used to split the tensor into number of chunks of some particular size. The size of each chunk produced is depends along which dimension we want split and equals to the length of tensor along that dimension divided by the number of chunk we want.\n",
        ">torch.chunk(input, chunks, dim=0) → List of Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IR4dn6lWra_a",
        "outputId": "ab3aedbf-d812-4351-9f59-ab0bd8a28313"
      },
      "source": [
        "# Example 1 - working\n",
        "a = torch.randn(3, 8)\n",
        "print (a)\n",
        "print (torch.chunk(a, 4, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0175, -1.0524, -0.9407, -1.0323,  0.5905, -1.1529, -0.4417,  0.0338],\n",
            "        [ 0.7468,  1.4089, -1.4058,  0.3404, -0.3751, -1.0404,  1.0926,  0.1809],\n",
            "        [ 0.6018,  1.3840, -0.3790, -2.0576, -1.3143,  1.2037, -1.0991, -2.2290]])\n",
            "(tensor([[ 0.0175, -1.0524],\n",
            "        [ 0.7468,  1.4089],\n",
            "        [ 0.6018,  1.3840]]), tensor([[-0.9407, -1.0323],\n",
            "        [-1.4058,  0.3404],\n",
            "        [-0.3790, -2.0576]]), tensor([[ 0.5905, -1.1529],\n",
            "        [-0.3751, -1.0404],\n",
            "        [-1.3143,  1.2037]]), tensor([[-0.4417,  0.0338],\n",
            "        [ 1.0926,  0.1809],\n",
            "        [-1.0991, -2.2290]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjzxcf3mra_a"
      },
      "source": [
        "Here the split is done along the x direction with the number of chunks equals to 4 and gives us the list of tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP6eGwJOra_b",
        "outputId": "342bd41e-ae27-473a-dc31-08ff457ca870"
      },
      "source": [
        "# Example 2 - working\n",
        "print (torch.chunk(a, 3, 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 0.0175, -1.0524, -0.9407],\n",
            "        [ 0.7468,  1.4089, -1.4058],\n",
            "        [ 0.6018,  1.3840, -0.3790]]), tensor([[-1.0323,  0.5905, -1.1529],\n",
            "        [ 0.3404, -0.3751, -1.0404],\n",
            "        [-2.0576, -1.3143,  1.2037]]), tensor([[-0.4417,  0.0338],\n",
            "        [ 1.0926,  0.1809],\n",
            "        [-1.0991, -2.2290]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGR5g-QNra_b"
      },
      "source": [
        "Here the unequal split is done because the number of columns present is eight and we want three chunks, which shows that they are not completely divisible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "j5GCxLz-ra_c",
        "outputId": "dd8d54b9-e797-4fc9-eeee-c20b30a62411"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/ankitsainiz865/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/ankitsainiz865/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_btWZkira_c"
      },
      "source": [
        "## Function 4 - TORCH.BERNOULLI\n",
        "\n",
        "Draws binary random numbers (0 or 1) from a Bernoulli distribution. The returned out tensor only has values 0 or 1 and is of the same shape as input. \n",
        ">torch.bernoulli(input, *, generator=None, out=None) → Tensor -\n",
        "Here the input is input tensor of probability values for the Bernoulli distribution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8wbwyP8ra_d",
        "outputId": "03ec2039-13a2-49fd-efec-3b329f29be48"
      },
      "source": [
        "# Example 1 - working\n",
        "a = torch.empty(3, 3).uniform_(0, 1) #creating empty matrix first & then uniform distribution of values in between 0 and 1 in empty matrix\n",
        "print (a)\n",
        "torch.bernoulli(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.9868, 0.8639, 0.6405],\n",
            "        [0.3957, 0.6360, 0.7827],\n",
            "        [0.7390, 0.5986, 0.2866]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [0., 1., 1.],\n",
              "        [1., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjpIAED9ra_d",
        "outputId": "2136f16b-4f7f-4c3a-e7c0-0a51d5a9d761"
      },
      "source": [
        "# Example 2 - working\n",
        "b = torch.empty(4, 5).uniform_(0, 1)\n",
        "print (b)\n",
        "torch.bernoulli(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1236, 0.7277, 0.4629, 0.1463, 0.9969],\n",
            "        [0.9675, 0.1984, 0.1434, 0.2616, 0.5140],\n",
            "        [0.5827, 0.8311, 0.4081, 0.4584, 0.5568],\n",
            "        [0.1367, 0.4905, 0.9550, 0.1213, 0.4280]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 0., 1.],\n",
              "        [1., 1., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 1.],\n",
              "        [0., 1., 1., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "gz9WvQ59ra_f",
        "outputId": "34c50335-067c-463f-f57e-a654146f33f3"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/ankitsainiz865/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/ankitsainiz865/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8niym_phra_f"
      },
      "source": [
        "## Function 5 - TORCH.RANDINT\n",
        "\n",
        "This function returns a tensor with randon integers generated between low (inclusive) and high (exclusive) and the shape of the ouput tensor is depends on the variable argument. Below the low is lowest integer to be drawn from the distribution with default value zero, high is one above the highest integer to be drawn from the distribution.\n",
        ">torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZt_rnuEra_g",
        "outputId": "dbb8a8c7-2d24-4858-90bf-6ca5387ff2eb"
      },
      "source": [
        "# Example 1 - working\n",
        "torch.randint(3, 5, (3,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2AY3VmZra_g"
      },
      "source": [
        "The ouput tensor is of the shape same as given in the function argument which is three and all values present in the matrix are in between the range [3, 5)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsIWy8jRra_g",
        "outputId": "b0046675-786c-43ef-849f-897a570c38e6"
      },
      "source": [
        "# Example 2 - working\n",
        "torch.randint(3, 10, (2, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 8],\n",
              "        [5, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sisf8KByra_h"
      },
      "source": [
        "Shape of ouput tensor 2 * 2, with values in between [3, 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "TbTCLhxjra_i",
        "outputId": "3f501a9b-a7f1-40c7-806e-bc51521cfa4d"
      },
      "source": [
        "# Example 3 - breaking (to illustrate when it breaks)\n",
        "torch.randint(3, 10, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-2a4f5f283725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (to illustrate when it breaks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: randint(): argument 'size' (position 2) must be tuple of ints, not int"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iX1Pyofra_k"
      },
      "source": [
        "Giving size as argument in the function is necessary otherwise error will pop-up if it's mistakenly left. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "f3VSCpUNra_l",
        "outputId": "39d7f1fb-75de-4629-bc21-5973a5bae4d9"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/ankitsainiz865/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/ankitsainiz865/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X1JzRddra_l"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Here we have covered various PyTorch functions that help in processing tensors, where tensors are a generalization of vectors and matrices and easily understood as a multidimensional array. There is an enormous number of functions that can be studied and perform, but here we describe five out of all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV0sdazfra_m"
      },
      "source": [
        "## Reference Links\n",
        "Provide links to your references and other interesting articles about tensors\n",
        "* Official documentation for tensor operations: https://pytorch.org/docs/stable/torch.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "t1M4E9rara_m",
        "outputId": "2d74fab8-1a38-4904-8d5d-4cf742f69407"
      },
      "source": [
        "jovian.commit(project='01-tensor-operations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Capturing environment..\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/ankitsainiz865/01-tensor-operations\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/ankitsainiz865/01-tensor-operations'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    }
  ]
}